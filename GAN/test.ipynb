{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdde981c-91d3-4533-8357-122eb4987a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88d236d-9a07-434f-a0fb-a2119558667b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "output_path = \"./output3\"\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.mkdir(output_path)\n",
    "\n",
    "# Load MNIST dataset\n",
    "# 28*28 숫자 이미지와 각 숫자가 무엇인지 Label data load\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data/mnist', train=True, download=True,\n",
    "                  transform=transforms.Compose([\n",
    "                      transforms.Resize(28),\n",
    "                      transforms.ToTensor(),\n",
    "                      transforms.Normalize([0.5], [0.5])\n",
    "                  ])\n",
    "                 ),\n",
    "    batch_size=bs, shuffle=True\n",
    ")\n",
    "\n",
    "# 시각화\n",
    "def visualize(img, epoch=0):\n",
    "    if img.shape[0] == 1:\n",
    "        plt.figure(figsize=(2,2))\n",
    "        img = img.squeeze()\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.show()\n",
    "    elif img.shape[0]>1 and len(img.shape)>2:\n",
    "        fig, axes = plt.subplots(2, 4, figsize=(12, 5))\n",
    "        for i, ax in enumerate(axes.flat):\n",
    "            ax.imshow(img[i].squeeze(), cmap='gray')\n",
    "            ax.axis('off')\n",
    "        plt.savefig(f'{output_path}/valid_{epoch}.png')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37926571-e60b-47e3-b29e-2e5f0132f63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 체크\n",
    "data = next(iter(dataloader))\n",
    "print(len(data))\n",
    "print(data[0].shape)\n",
    "print(data[1].shape)\n",
    "print(data[1][0])\n",
    "\n",
    "visualize(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8d3eb2-9f16-4e45-a7fb-1dd1cdd026e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generative\n",
    "# noise variable을 입력으로 받아서, 이미지를 출력한다 = 28*28\n",
    "class Generator(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Generator class for GAN\n",
    "    latent vector를 입력으로 받아서 28*28 vector를 출력한다.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(100, 256),\n",
    "            torch.nn.LeakyReLU(0.2),\n",
    "            torch.nn.Linear(256, 512),\n",
    "            torch.nn.LeakyReLU(0.2),\n",
    "            torch.nn.Linear(512, 1024),\n",
    "            torch.nn.LeakyReLU(0.2),\n",
    "            torch.nn.Linear(1024, 784),\n",
    "            torch.nn.Tanh()  # Outputs in range [-1, 1] to match the preprocessed MNIST images\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        output = self.model(z)\n",
    "        return output.view(-1, 1, 28, 28)\n",
    "\n",
    "G = Generator().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df34778-1548-4846-bf78-74eff0ec569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_latent = torch.ones(64, 100).to(device)\n",
    "\n",
    "random_out = G(test_latent)\n",
    "print(random_out.shape)\n",
    "visualize(random_out[0].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4346f9b0-1f90-4a0a-a388-0aa76e149bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminative\n",
    "# 이미지를 입력으로 받아서, scalar 값을 출력한다. 실제 데이터면 0로, 가짜 데이터면 1로\n",
    "\n",
    "class Discriminative(torch.nn.Module):\n",
    "    def __init__(self, res=784):\n",
    "        super(Discriminative, self).__init__()\n",
    "        self.res = res\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(res, 1024),\n",
    "            torch.nn.LeakyReLU(0.2),\n",
    "            torch.nn.Linear(1024, 256),\n",
    "            torch.nn.LeakyReLU(0.2),\n",
    "            torch.nn.Linear(256, 64),\n",
    "            torch.nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            torch.nn.Linear(64, 1),\n",
    "            torch.nn.Sigmoid() # 값을 0~1로 제한\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.res)\n",
    "        feature = self.model(x)\n",
    "        clas = self.classifier(feature)\n",
    "        return clas, feature\n",
    "\n",
    "D = Discriminative().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bddfdfd-ab35-49a9-b330-f5dd5065f2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, _ = D(random_out)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d643f07-0c8b-4242-966d-d9fecb430f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "epochs = 50\n",
    "k = 1\n",
    "criterion = torch.nn.BCELoss()\n",
    "feat_loss_ft = torch.nn.functional.mse_loss\n",
    "\n",
    "optimizer_d = torch.optim.Adam(D.parameters(), lr=0.0005, betas=(0.5, 0.999))\n",
    "optimizer_g = torch.optim.Adam(G.parameters(), lr=0.0005, betas=(0.5, 0.999))\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer_g, step_size=10, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b7539e-d76c-41a2-9d27-cdb9ecbc055b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0].shape\n",
    "\n",
    "pred, _ = D(data[0].to(device))\n",
    "print(pred.shape)\n",
    "\n",
    "real_labels = torch.ones(bs, device=device)\n",
    "criterion(pred.squeeze()[:4], real_labels[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6047a7a-10f9-40e2-ae92-cb5d63772ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_losses = []\n",
    "generative_losses = []\n",
    "correction_rates = []\n",
    "\n",
    "pbar = tqdm(total=len(dataloader), desc=\"Training Progress\")\n",
    "for epoch in range(epochs):\n",
    "    d_loss = 0\n",
    "    g_loss = 0\n",
    "    corrent_nums = 0\n",
    "    \n",
    "    for idx, data in enumerate(dataloader):\n",
    "        real_images = data[0].to(device)\n",
    "        if real_images.shape[0] != bs:\n",
    "            continue\n",
    "        # print(\"real_images : \", real_images.shape)\n",
    "        \n",
    "        real_labels = torch.ones(bs, device=device) * 0.9 # 1 => 0.9 , one-sided label smoothing\n",
    "        fake_labels = torch.zeros(bs, device=device)\n",
    "        \n",
    "        for step in range(k):\n",
    "            D.zero_grad()\n",
    "            noise = torch.randn(bs, 100, device=device)\n",
    "            fake_images = G(noise)\n",
    "            real_pred, real_ft = D(real_images)\n",
    "            fake_pred, _ = D(fake_images)\n",
    "\n",
    "            loss_real_samples = criterion(real_pred.squeeze(), real_labels)\n",
    "            loss_fake_samples = criterion(fake_pred.squeeze(), fake_labels)\n",
    "\n",
    "            corrent_nums += torch.sum(torch.where(fake_pred.squeeze() > 0.5, 1, 0)).cpu().detach().numpy()\n",
    "\n",
    "            loss = (loss_real_samples + loss_fake_samples)/(bs*2)\n",
    "            if idx%100==99:\n",
    "                tqdm.write(f\"D_loss : {d_loss.cpu().detach().numpy()/100}\")\n",
    "                discriminator_losses.append(d_loss.cpu().detach().numpy()/100)\n",
    "                d_loss=0\n",
    "\n",
    "            # backward and optimizer D\n",
    "            loss.backward()\n",
    "            optimizer_d.step()\n",
    "            d_loss += loss\n",
    "\n",
    "        G.zero_grad()\n",
    "        noise = torch.randn(bs, 100, device=device)\n",
    "        generated_images = G(noise)\n",
    "        preds, fake_ft = D(generated_images)\n",
    "        \n",
    "        # ft_loss = feat_loss_ft(fake_ft.cpu().detach(), real_ft.cpu().detach())\n",
    "        loss = criterion(preds.squeeze(), real_labels)\n",
    "        \n",
    "        if idx%100==99:\n",
    "            tqdm.write(f\"G_loss : {g_loss.cpu().detach().numpy()/100}\")\n",
    "            generative_losses.append(g_loss.cpu().detach().numpy()/100)\n",
    "            g_loss=0\n",
    "\n",
    "        # backward and optimizer G\n",
    "        loss.backward()\n",
    "        optimizer_g.step()\n",
    "        g_loss += loss\n",
    "\n",
    "        pbar.update(1)\n",
    "\n",
    "    scheduler.step()\n",
    "    correction_rates.append(corrent_nums/(len(dataloader)*bs))\n",
    "    \n",
    "    plt.title(\"Discriminator loss\")\n",
    "    plt.plot(discriminator_losses)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.title(\"Generator loss\")\n",
    "    plt.plot(generative_losses)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.title(\"Correction rates\")\n",
    "    plt.plot(correction_rates)\n",
    "    plt.show()\n",
    "    plt.savefig(f\"{output_path}/correction_rates.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # evaluate\n",
    "    noise = torch.randn(8, 100, device=device)\n",
    "    generated_images = G(noise)\n",
    "    visualize(generated_images.cpu().detach().numpy(), epoch)\n",
    "\n",
    "    loss_text = f\"\\nEpoch : {epoch} Generator : {sum(generative_losses)/len(generative_losses)}  |  Discriminator : {sum(discriminator_losses)/len(discriminator_losses)}\"\n",
    "    with open(f'{output_path}/loss.txt', 'a') as file:\n",
    "        file.write(loss_text)\n",
    "\n",
    "    del noise\n",
    "    del generated_images\n",
    "    \n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13574e37-72cc-49da-80a2-2a486c31ba10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23d86a7-4bbe-4b10-a574-f1c545d70b55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
